{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02974db-423f-40c4-b7e4-5031bae7e399",
   "metadata": {},
   "source": [
    "# Text Summerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78167017-5f0b-4663-a8fc-c0cf9340ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install required libraries \n",
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec20526-0fc1-43fb-80dc-84c2d988a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub[hf_xet] --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd0a76a9-34f5-41a0-844e-9d5947da2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import libraries\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8748838f-2db5-435f-beea-f5ed80193983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load summarization pipeline using pretrained BART model\n",
    "def load_summarizer():\n",
    "    model_name = \"facebook/bart-large-cnn\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "    print(f\"‚úÖ Loaded summarization model: {model_name}\")\n",
    "    return summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98fd8dca-6a0f-4c6b-ad8a-19d709ec40fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded summarization model: facebook/bart-large-cnn\n"
     ]
    }
   ],
   "source": [
    "summarizer = load_summarizer()\n",
    "\n",
    "# Step 4: Define text summarization function\n",
    "def summarize_text(text, max_len=130, min_len=30):\n",
    "    summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)\n",
    "    return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa60d6ea-92de-45cb-bcd2-cee7abd6105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define lightweight keyword extractor (no NLTK required)\n",
    "def extract_keywords_basic(text, num_keywords=5):\n",
    "    text = text.lower()\n",
    "    words = re.findall(r'\\b[a-z]{3,}\\b', text)\n",
    "    stopwords_set = set([\n",
    "        \"the\", \"and\", \"was\", \"for\", \"with\", \"that\", \"from\", \"after\", \"this\", \"which\", \"had\",\n",
    "        \"were\", \"have\", \"been\", \"they\", \"their\", \"not\", \"are\", \"his\", \"her\", \"has\", \"but\", \"you\"\n",
    "    ])\n",
    "    filtered_words = [word for word in words if word not in stopwords_set]\n",
    "    freq = {}\n",
    "    for word in filtered_words:\n",
    "        freq[word] = freq.get(word, 0) + 1\n",
    "    top_keywords = sorted(freq, key=freq.get, reverse=True)[:num_keywords]\n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a6ef7c-cec0-4167-9753-f6ab337056ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 76. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n"
     ]
    }
   ],
   "source": [
    "# üìù Step 6: Input your text here\n",
    "input_text = \"\"\"\n",
    "The Apollo program was the third United States human spaceflight program carried out by NASA,\n",
    "which succeeded in landing the first humans on the Moon from 1969 to 1972.\n",
    "Apollo was first conceived during the Eisenhower administration and began in earnest after President John F. Kennedy's 1961 speech.\n",
    "It was the third human spaceflight program after Mercury and Gemini.\n",
    "\"\"\"\n",
    "\n",
    "# üöÄ Step 7: Run summarization and keyword extraction\n",
    "summary = summarize_text(input_text)\n",
    "keywords = extract_keywords_basic(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cadaed4-5dbe-4111-b5bc-8781baa7ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Original Text:\n",
      " The Apollo program was the third United States human spaceflight program carried out by NASA,\n",
      "which succeeded in landing the first humans on the Moon from 1969 to 1972.\n",
      "Apollo was first conceived during the Eisenhower administration and began in earnest after President John F. Kennedy's 1961 speech.\n",
      "It was the third human spaceflight program after Mercury and Gemini.\n",
      "\n",
      "üìå Summary:\n",
      " The Apollo program was the third U.S. human spaceflight program carried out by NASA. It succeeded in landing the first humans on the Moon from 1969 to 1972.\n",
      "\n",
      "üîë Top Keywords: program, apollo, third, human, spaceflight\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Display results\n",
    "print(\"\\nüßæ Original Text:\\n\", input_text.strip())\n",
    "print(\"\\nüìå Summary:\\n\", summary.strip())\n",
    "print(\"\\nüîë Top Keywords:\", \", \".join(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec195e-b33a-46f1-858c-9718d36f7784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
